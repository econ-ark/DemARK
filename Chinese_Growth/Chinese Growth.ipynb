{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "China's high net saving rate (approximately 25%) is a puzzle for economists, particularly in \n",
    "light of a consistently high income growth rate.\n",
    "\n",
    "If the last exercise made you worry that invoking difficult-to-measure \"uncertainty\" can explain\n",
    "anything (e.g. \"the stock market fell today because the risk aversion of the representative \n",
    "agent increased\"), the next exercise may reassure you.  It is designed to show that there are \n",
    "limits to the phenomena that can be explained by invoking uncertainty.\n",
    " \n",
    "It asks \"what beliefs about uncertainty would Chinese consumers need to hold in order to generate a\n",
    "saving rate of 25%, given the rapid pace of Chinese growth\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create the ConsumerType we want to solve the model for.\n",
    "\n",
    "Model set up:\n",
    "\n",
    "- \"Standard\" infinite horizon consumption/savings model, with mortality and permanent and temporary shocks to income\n",
    "- Markov state that represents the state of the Chinese economy (to be detailed later)\n",
    "- Ex-ante heterogeneity in consumers' discount factors\n",
    "\n",
    "In our experiment, consumers will live in a stationary, low-growth environment (intended to approximate China before 1978).  Then, unexpectedly, income growth will surge at the same time that income uncertainty increases (intended to approximate the effect of economic reforms in China since 1978.)  Consumers believe the high-growth, high-uncertainty state is highly persistent, but temporary.\n",
    "\n",
    "HARK's MarkovConsumerType will be a very convient way to run this experiment.  So we need to prepare the parameters to create that ConsumerType, and then create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from util import log_progress\n",
    "\n",
    "# The first step is to be able to bring things in from different directories\n",
    "import sys \n",
    "import os\n",
    "# Get the path to HARK either from an env variable or use the default. Remove this\n",
    "# once HARK is pip installable\n",
    "HARK_PATH = os.path.abspath(os.path.join('..', os.environ.get('HARK_PATH', '../HARK')))\n",
    "\n",
    "sys.path.insert(0, os.path.join(HARK_PATH, 'ConsumptionSaving')) #Path to ConsumptionSaving folder\n",
    "sys.path.insert(0, HARK_PATH)\n",
    "\n",
    "# Initialize the cstwMPC parameters\n",
    "from copy import deepcopy\n",
    "init_infinite = {\n",
    "    \"CRRA\":1.0,                    # Coefficient of relative risk aversion   \n",
    "    \"Rfree\":1.01/(1.0 - 1.0/160.0), # Survival probability,\n",
    "    \"PermGroFac\":[1.000**0.25], # Permanent income growth factor (no perm growth),\n",
    "    \"PermGroFacAgg\":1.0,\n",
    "    \"BoroCnstArt\":0.0,\n",
    "    \"CubicBool\":False,\n",
    "    \"vFuncBool\":False,\n",
    "    \"PermShkStd\":[(0.01*4/11)**0.5],  # Standard deviation of permanent shocks to income\n",
    "    \"PermShkCount\":5,  # Number of points in permanent income shock grid\n",
    "    \"TranShkStd\":[(0.01*4)**0.5],  # Standard deviation of transitory shocks to income,\n",
    "    \"TranShkCount\":5,  # Number of points in transitory income shock grid\n",
    "    \"UnempPrb\":0.07,  # Probability of unemployment while working\n",
    "    \"IncUnemp\":0.15,  # Unemployment benefit replacement rate\n",
    "    \"UnempPrbRet\":None,\n",
    "    \"IncUnempRet\":None,\n",
    "    \"aXtraMin\":0.00001,  # Minimum end-of-period assets in grid\n",
    "    \"aXtraMax\":20,  # Maximum end-of-period assets in grid\n",
    "    \"aXtraCount\":20,  # Number of points in assets grid,\n",
    "    \"aXtraExtra\":[None],\n",
    "    \"aXtraNestFac\":3,  # Number of times to 'exponentially nest' when constructing assets grid\n",
    "    \"LivPrb\":[1.0 - 1.0/160.0],  # Survival probability\n",
    "    \"DiscFac\":0.97,             # Default intertemporal discount factor, # dummy value, will be overwritten\n",
    "    \"cycles\":0,\n",
    "    \"T_cycle\":1,\n",
    "    \"T_retire\":0,\n",
    "    'T_sim':1200,  # Number of periods to simulate (idiosyncratic shocks model, perpetual youth)\n",
    "    'T_age': 400,\n",
    "    'IndL': 10.0/9.0,  # Labor supply per individual (constant),\n",
    "    'aNrmInitMean':np.log(0.00001),\n",
    "    'aNrmInitStd':0.0,\n",
    "    'pLvlInitMean':0.0,\n",
    "    'pLvlInitStd':0.0,\n",
    "    'AgentCount':0,  # will be overwritten by parameter distributor\n",
    "}\n",
    "\n",
    "init_China_parameters = deepcopy(init_infinite)\n",
    "\n",
    "\n",
    "# For a Markov model, we need a Markov transition array.  Create that array.\n",
    "# Remember, for this simple example, we just have a low-growth state, and a high-growth state\n",
    "StateCount                      = 2 #number of Markov states\n",
    "ProbGrowthEnds                  = (1./160.) #probability agents assign to the high-growth state ending\n",
    "MrkvArray                       = np.array([[1.,0.],[ProbGrowthEnds,1.-ProbGrowthEnds]]) #Markov array\n",
    "init_China_parameters['MrkvArray'] = [MrkvArray] #assign the Markov array as a parameter\n",
    "\n",
    "\n",
    "# One other parameter to change: the number of agents in simulation\n",
    "# We want to increase this, because later on when we vastly increase the variance of the permanent\n",
    "# income shock, things get wonky.\n",
    "# It is important to note that we need to change this value here, before we have used the parameters\n",
    "# to initialize the MarkovConsumerType.  This is because this parameter is used during initialization.\n",
    "# Other parameters that are not used during initialization can also be assigned here,\n",
    "# by changing the appropriate value in the init_China_parameters_dictionary; however,\n",
    "# they can also be changed later, by altering the appropriate attribute of the initialized\n",
    "# MarkovConsumerType.\n",
    "init_China_parameters['AgentCount']   = 10000\n",
    "\n",
    "### Import and initialize the HARK ConsumerType we want \n",
    "### Here, we bring in an agent making a consumption/savings decision every period, subject\n",
    "### to transitory and permanent income shocks, AND a Markov shock\n",
    "from ConsMarkovModel import MarkovConsumerType\n",
    "ChinaExample = MarkovConsumerType(**init_China_parameters)\n",
    "\n",
    "# Currently, Markov states can differ in their interest factor, permanent growth factor, \n",
    "# survival probability, and income distribution.  Each of these needs to be specifically set.  \n",
    "# Do that here, except income distribution.  That will be done later, because we want to examine\n",
    "# the effects of different income distributions.\n",
    "\n",
    "ChinaExample.assignParameters(PermGroFac = [np.array([1.,1.06 ** (.25)])], #needs to be a list, with 0th element of shape of shape (StateCount,)\n",
    "                              Rfree      = np.array(StateCount*[init_China_parameters['Rfree']]), #need to be an array, of shape (StateCount,)\n",
    "                              LivPrb     = [np.array(StateCount*[init_China_parameters['LivPrb']][0])], #needs to be a list, with 0th element of shape of shape (StateCount,)\n",
    "                              cycles     = 0)\n",
    "ChinaExample.track_vars = ['aNrmNow','cNrmNow','pLvlNow'] # Names of variables to be tracked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add in ex-ante heterogeneity in consumers' discount factors\n",
    "\n",
    "The cstwMPC parameters do not define a discount factor, since there is ex-ante heterogeneity in the discount factor.  To prepare to create this ex-ante heterogeneity, first create the desired number of consumer types:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_consumer_types   = 7 # declare the number of types we want\n",
    "ChineseConsumerTypes = [] # initialize an empty list\n",
    "\n",
    "for nn in log_progress(range(num_consumer_types), every=1):\n",
    "    # Now create the types, and append them to the list ChineseConsumerTypes\n",
    "    newType = deepcopy(ChinaExample)    \n",
    "    ChineseConsumerTypes.append(newType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, generate the desired ex-ante heterogeneity, by giving the different consumer types each with their own discount factor.\n",
    "\n",
    "First, decide the discount factors to assign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HARKutilities import approxUniform\n",
    "\n",
    "bottomDiscFac = 0.9800\n",
    "topDiscFac    = 0.9934 \n",
    "DiscFac_list  = approxUniform(N=num_consumer_types,bot=bottomDiscFac,top=topDiscFac)[1]\n",
    "\n",
    "# Now, assign the discount factors we want to the ChineseConsumerTypes\n",
    "for j in log_progress(range(num_consumer_types), every=1):\n",
    "    ChineseConsumerTypes[j].DiscFac = DiscFac_list[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write the function to perform the experiment.\n",
    "\n",
    "Recall that all parameters have been assigned appropriately, except for the income process.\n",
    "\n",
    "This is because we want to see how much uncertainty needs to accompany the high-growth state to generate the desired high savings rate.\n",
    "\n",
    "Therefore, among other things, this function will have to initialize and assign the appropriate income process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the income distribution in the low-growth state, which we will not change\n",
    "from ConsIndShockModel import constructLognormalIncomeProcessUnemployment\n",
    "import ConsumerParameters as IncomeParams\n",
    "\n",
    "LowGrowthIncomeDstn  = constructLognormalIncomeProcessUnemployment(IncomeParams)[0][0]\n",
    "\n",
    "# Remember the standard deviation of the permanent income shock in the low-growth state for later\n",
    "LowGrowth_PermShkStd = IncomeParams.PermShkStd\n",
    "\n",
    "\n",
    "\n",
    "def calcNatlSavingRate(PrmShkVar_multiplier,RNG_seed = 0):\n",
    "    \"\"\"\n",
    "    This function actually performs the experiment we want.\n",
    "    \n",
    "    Remember this experiment is: get consumers into the steady-state associated with the low-growth\n",
    "    regime. Then, give them an unanticipated shock that increases the income growth rate\n",
    "    and permanent income uncertainty at the same time.  What happens to the path for \n",
    "    the national saving rate?  Can an increase in permanent income uncertainty\n",
    "    explain the high Chinese saving rate since economic reforms began?\n",
    "    \n",
    "    The inputs are:\n",
    "        * PrmShkVar_multiplier, the number by which we want to multiply the variance\n",
    "          of the permanent shock in the low-growth state to get the variance of the\n",
    "          permanent shock in the high-growth state\n",
    "        * RNG_seed, an integer to seed the random number generator for simulations.  This useful\n",
    "          because we are going to run this function for different values of PrmShkVar_multiplier,\n",
    "          and we may not necessarily want the simulated agents in each run to experience\n",
    "          the same (normalized) shocks.\n",
    "    \"\"\"\n",
    "\n",
    "    # First, make a deepcopy of the ChineseConsumerTypes (each with their own discount factor), \n",
    "    # because we are going to alter them\n",
    "    ChineseConsumerTypesNew = deepcopy(ChineseConsumerTypes)\n",
    "\n",
    "    # Set the uncertainty in the high-growth state to the desired amount, keeping in mind\n",
    "    # that PermShkStd is a list of length 1\n",
    "    PrmShkStd_multiplier    = PrmShkVar_multiplier ** .5\n",
    "    IncomeParams.PermShkStd = [LowGrowth_PermShkStd[0] * PrmShkStd_multiplier] \n",
    "\n",
    "    # Construct the appropriate income distributions\n",
    "    HighGrowthIncomeDstn = constructLognormalIncomeProcessUnemployment(IncomeParams)[0][0]\n",
    "\n",
    "    # To calculate the national saving rate, we need national income and national consumption\n",
    "    # To get those, we are going to start national income and consumption at 0, and then\n",
    "    # loop through each agent type and see how much they contribute to income and consumption.\n",
    "    NatlIncome = 0.\n",
    "    NatlCons   = 0.\n",
    "\n",
    "    for ChineseConsumerTypeNew in ChineseConsumerTypesNew:\n",
    "        ### For each consumer type (i.e. each discount factor), calculate total income \n",
    "        ### and consumption\n",
    "\n",
    "        # First give each ConsumerType their own random number seed\n",
    "        RNG_seed += 19\n",
    "        ChineseConsumerTypeNew.seed  = RNG_seed\n",
    "        \n",
    "        # Set the income distribution in each Markov state appropriately        \n",
    "        ChineseConsumerTypeNew.IncomeDstn = [[LowGrowthIncomeDstn,HighGrowthIncomeDstn]]\n",
    "\n",
    "        # Solve the problem for this ChineseConsumerTypeNew\n",
    "        ChineseConsumerTypeNew.solve()\n",
    "\n",
    "        \"\"\"\n",
    "        Now we are ready to simulate.\n",
    "        \n",
    "        This case will be a bit different than most, because agents' *perceptions* of the probability\n",
    "        of changes in the Chinese economy will differ from the actual probability of changes.  \n",
    "        Specifically, agents think there is a 0% chance of moving out of the low-growth state, and \n",
    "        that there is a  (1./160) chance of moving out of the high-growth state.  In reality, we \n",
    "        want the Chinese economy to reach the low growth steady state, and then move into the \n",
    "        high growth state with probability 1.  Then we want it to persist in the high growth \n",
    "        state for 40 years. \n",
    "        \"\"\"\n",
    "        \n",
    "        ## Now, simulate 500 quarters to get to steady state, then 40 years of high growth\n",
    "        ChineseConsumerTypeNew.T_sim = 660 \n",
    "        \n",
    "        # Ordinarily, the simulate method for a MarkovConsumerType randomly draws Markov states\n",
    "        # according to the transition probabilities in MrkvArray *independently* for each simulated\n",
    "        # agent.  In this case, however, we want the discrete state to be *perfectly coordinated*\n",
    "        # across agents-- it represents a macroeconomic state, not a microeconomic one!  In fact,\n",
    "        # we don't want a random history at all, but rather a specific, predetermined history: 125\n",
    "        # years of low growth, followed by 40 years of high growth.\n",
    "        \n",
    "        # To do this, we're going to \"hack\" our consumer type a bit.  First, we set the attribute\n",
    "        # MrkvPrbsInit so that all of the initial Markov states are in the low growth state.  Then\n",
    "        # we initialize the simulation and run it for 500 quarters.  However, as we do not\n",
    "        # want the Markov state to change during this time, we change its MrkvArray to always be in\n",
    "        # the low growth state with probability 1.\n",
    "        \n",
    "        ChineseConsumerTypeNew.MrkvPrbsInit = np.array([1.0,0.0]) # All consumers born in low growth state\n",
    "        ChineseConsumerTypeNew.MrkvArray[0] = np.array([[1.0,0.0],[1.0,0.0]]) # Stay in low growth state\n",
    "        ChineseConsumerTypeNew.initializeSim() # Clear the history and make all newborn agents\n",
    "        ChineseConsumerTypeNew.simulate(500)   # Simulate 500 quarders of data\n",
    "        \n",
    "        # Now we want the high growth state to occur for the next 160 periods.  We change the initial\n",
    "        # Markov probabilities so that any agents born during this time (to replace an agent who\n",
    "        # died) is born in the high growth state.  Moreover, we change the MrkvArray to *always* be\n",
    "        # in the high growth state with probability 1.  Then we simulate 160 more quarters.\n",
    "        \n",
    "        ChineseConsumerTypeNew.MrkvPrbsInit = np.array([0.0,1.0]) # All consumers born in low growth state\n",
    "        ChineseConsumerTypeNew.MrkvArray[0] = np.array([[0.0,1.0],[0.0,1.0]]) # Stay in low growth state\n",
    "        ChineseConsumerTypeNew.simulate(160)   # Simulate 160 quarders of data\n",
    "    \n",
    "        # Now, get the aggregate income and consumption of this ConsumerType over time\n",
    "        IncomeOfThisConsumerType = np.sum((ChineseConsumerTypeNew.aNrmNow_hist*ChineseConsumerTypeNew.pLvlNow_hist*\n",
    "                                          (ChineseConsumerTypeNew.Rfree[0] - 1.)) +\n",
    "                                           ChineseConsumerTypeNew.pLvlNow_hist, axis=1)\n",
    "        \n",
    "        ConsOfThisConsumerType = np.sum(ChineseConsumerTypeNew.cNrmNow_hist*ChineseConsumerTypeNew.pLvlNow_hist,axis=1)\n",
    "        \n",
    "        # Add the income and consumption of this ConsumerType to national income and consumption\n",
    "        NatlIncome     += IncomeOfThisConsumerType\n",
    "        NatlCons       += ConsOfThisConsumerType\n",
    "\n",
    "        \n",
    "    # After looping through all the ConsumerTypes, calculate and return the path of the national \n",
    "    # saving rate\n",
    "    NatlSavingRate = (NatlIncome - NatlCons)/NatlIncome\n",
    "\n",
    "    return NatlSavingRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the function we just defined to calculate the path of the national saving rate following the economic reforms, for a given value of the increase to the variance of permanent income accompanying the reforms.  We are going to graph this path for various values for this increase.\n",
    "\n",
    "Remember, we want to see if any plausible value for this increase can explain the high Chinese saving rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the number of periods before the reforms to plot in the graph\n",
    "quarters_before_reform_to_plot = 5\n",
    "\n",
    "# Declare the quarters we want to plot results for\n",
    "quarters_to_plot = np.arange(-quarters_before_reform_to_plot ,160,1)\n",
    "\n",
    "# Create a list to hold the paths of the national saving rate\n",
    "NatlSavingsRates = []\n",
    "\n",
    "# Create a list of floats to multiply the variance of the permanent shock to income by\n",
    "PermShkVarMultipliers = (1.,2.,4.,8.,11.)\n",
    "\n",
    "# Loop through the desired multipliers, then get the path of the national saving rate\n",
    "# following economic reforms, assuming that the variance of the permanent income shock\n",
    "# was multiplied by the given multiplier\n",
    "index = 0\n",
    "for PermShkVarMultiplier in log_progress(PermShkVarMultipliers, every=1):\n",
    "    NatlSavingsRates.append(calcNatlSavingRate(PermShkVarMultiplier,RNG_seed = index)[-160 - quarters_before_reform_to_plot :])\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've calculated the path of the national saving rate as we wanted. All that's left is to graph the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('Natl Savings Rate')\n",
    "plt.xlabel('Quarters Since Economic Reforms')\n",
    "plt.plot(quarters_to_plot,NatlSavingsRates[0],label=str(PermShkVarMultipliers[0]) + ' x variance')\n",
    "plt.plot(quarters_to_plot,NatlSavingsRates[1],label=str(PermShkVarMultipliers[1]) + ' x variance')\n",
    "plt.plot(quarters_to_plot,NatlSavingsRates[2],label=str(PermShkVarMultipliers[2]) + ' x variance')\n",
    "plt.plot(quarters_to_plot,NatlSavingsRates[3],label=str(PermShkVarMultipliers[3]) + ' x variance')\n",
    "plt.plot(quarters_to_plot,NatlSavingsRates[4],label=str(PermShkVarMultipliers[4]) + ' x variance')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "ncol=2, mode=\"expand\", borderaxespad=0.) #put the legend on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
